{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a209bf3",
   "metadata": {
    "papermill": {
     "duration": 0.005261,
     "end_time": "2024-10-26T09:07:14.655508",
     "exception": false,
     "start_time": "2024-10-26T09:07:14.650247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Importing Libraries and Setting Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03946ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T09:07:14.666484Z",
     "iopub.status.busy": "2024-10-26T09:07:14.666114Z",
     "iopub.status.idle": "2024-10-26T09:07:21.240825Z",
     "shell.execute_reply": "2024-10-26T09:07:21.239869Z"
    },
    "papermill": {
     "duration": 6.58281,
     "end_time": "2024-10-26T09:07:21.243231",
     "exception": false,
     "start_time": "2024-10-26T09:07:14.660421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The torch modules are used for the Nueral Network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#From this libraries, models will give us Resnet34 which will be used for Feature Extraction\n",
    "# and in DL tasks, transforms library is used to make the images usable for the models\n",
    "from torchvision import models, transforms\n",
    "#DataLoader is used to create the DataLoader object used for DL tasks\n",
    "#ConcatDataset to create a concatenated dataset of all the three folds in the Dataset\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "#ImageFolder module is used to create labelled data from the testing_data\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "#SVC, LogisticRegression, DecisionTree are the modules provided my sklearn for ML application\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#VotingClassifier is an ensemble method.\n",
    "#Ensemble means it aggregates the output of all the three ML models and then selects\n",
    "#the output depending on all the three's output(in our case)\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862bde4",
   "metadata": {
    "papermill": {
     "duration": 0.004474,
     "end_time": "2024-10-26T09:07:21.252651",
     "exception": false,
     "start_time": "2024-10-26T09:07:21.248177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Loading And Preprocessing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd65aba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T09:07:21.263462Z",
     "iopub.status.busy": "2024-10-26T09:07:21.262998Z",
     "iopub.status.idle": "2024-10-26T09:07:30.142503Z",
     "shell.execute_reply": "2024-10-26T09:07:30.141644Z"
    },
    "papermill": {
     "duration": 8.887513,
     "end_time": "2024-10-26T09:07:30.144821",
     "exception": false,
     "start_time": "2024-10-26T09:07:21.257308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Here, transforms.Compose is used to create the images in a uniform manner\n",
    "transform = transforms.Compose([\n",
    "    # Resize to match ResNet's input size\n",
    "    transforms.Resize((224, 224)), \n",
    "    #This creates into Tensor\n",
    "    transforms.ToTensor(),\n",
    "    # ImageNet normalization for Z-Score Normalization\n",
    "    #Images have three channels RGB and so three values of mean and std for individual channel\n",
    "    #Z-Score=val-mean/std\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#Here we are reading the images from each and every fold to create our testing data\n",
    "#ImageFolder is for labeled data creation, it works like in our case we are having\n",
    "#images under two folders all and hem, so it creates label in alphabetical order, all-0 & hem-1\n",
    "#Now, the images under each folder will be assigned that specific label\n",
    "fold_0_data = ImageFolder(\"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0\", transform=transform)\n",
    "fold_1_data = ImageFolder(\"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1\", transform=transform)\n",
    "fold_2_data = ImageFolder(\"/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2\", transform=transform)\n",
    "\n",
    "train_dataset = ConcatDataset([fold_0_data, fold_1_data, fold_2_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ce1e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T09:07:30.156024Z",
     "iopub.status.busy": "2024-10-26T09:07:30.155455Z",
     "iopub.status.idle": "2024-10-26T09:07:30.187708Z",
     "shell.execute_reply": "2024-10-26T09:07:30.186971Z"
    },
    "papermill": {
     "duration": 0.039908,
     "end_time": "2024-10-26T09:07:30.189632",
     "exception": false,
     "start_time": "2024-10-26T09:07:30.149724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Custom Dataset class for validation data\n",
    "#While working with custom dataset, it is compulsary to have __init__,__len__,__getitem__ methods\n",
    "#Here this class inherits Dataset class\n",
    "class ValidationDataset(Dataset):\n",
    "    #Init method will have inclusive call, self is self's insatance\n",
    "    #img_dir is the path to testing data, #labels_csv path to labels data for testing data\n",
    "    #transform is if we pass any transform function(made above), else none as default\n",
    "    def __init__(self, img_dir, labels_csv, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.labels = pd.read_csv(labels_csv)\n",
    "\n",
    "        # Now here, labels is having name and label of that specific image\n",
    "        #In our case, all is 0 and hem is 1 but in test_labels we have 1 as all and 0 as hem\n",
    "        #So we are inverting them\n",
    "        self.labels['labels'] = self.labels['labels'].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image path and label\n",
    "        img_name = os.path.join(self.img_dir, self.labels.iloc[idx, 1])  # Assuming column 1 contains image names\n",
    "        image = Image.open(img_name).convert(\"RGB\")  # Load the image in RGB mode\n",
    "        label = int(self.labels.iloc[idx, 2])  # Assuming column 2 contains the modified label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Load the validation dataset\n",
    "validation_dir = \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data\"\n",
    "validation_dataset = ValidationDataset(validation_dir, \n",
    "                                       \"/kaggle/input/leukemia-classification/C-NMC_Leukemia/validation_data/C-NMC_test_prelim_phase_data_labels.csv\", \n",
    "                                       transform=transform)\n",
    "\n",
    "# Load the validation data using DataLoader\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705a646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T09:07:30.201249Z",
     "iopub.status.busy": "2024-10-26T09:07:30.200970Z",
     "iopub.status.idle": "2024-10-26T09:07:31.521772Z",
     "shell.execute_reply": "2024-10-26T09:07:31.520831Z"
    },
    "papermill": {
     "duration": 1.329691,
     "end_time": "2024-10-26T09:07:31.524013",
     "exception": false,
     "start_time": "2024-10-26T09:07:30.194322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to unnormalize and display an image\n",
    "def imshow(image, label):\n",
    "    # Convert image to numpy for displaying\n",
    "    image = image.numpy().transpose((1, 2, 0))  # Change dimensions to Height x Width x Channels\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean  # Unnormalize the image\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Label: {label}')\n",
    "    plt.show()\n",
    "\n",
    "# Iterate over the first few samples in the ConcatDataset and display them\n",
    "for i in range(4):  # Display first 4 samples\n",
    "    image, label = train_dataset[i]\n",
    "    imshow(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5034dc4",
   "metadata": {
    "papermill": {
     "duration": 0.007683,
     "end_time": "2024-10-26T09:07:31.539777",
     "exception": false,
     "start_time": "2024-10-26T09:07:31.532094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Using Resnet34 Model for Features Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6097eda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T09:07:31.557412Z",
     "iopub.status.busy": "2024-10-26T09:07:31.556568Z",
     "iopub.status.idle": "2024-10-26T09:09:56.354358Z",
     "shell.execute_reply": "2024-10-26T09:09:56.353351Z"
    },
    "papermill": {
     "duration": 144.818603,
     "end_time": "2024-10-26T09:09:56.366139",
     "exception": false,
     "start_time": "2024-10-26T09:07:31.547536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataLoader for the training dataset to handle batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "resnet = models.resnet34(pretrained=True)\n",
    "\n",
    "# Remove the final fully connected layer (fc) so we only use the convolutional layers for feature extraction\n",
    "feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "# Set the model to evaluation mode (we don't want to train it)\n",
    "#Setting it into eval mode will make sure that the gradients aren't stored or calculated\n",
    "#as we don'w want to backprop them\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Function to extract features from the DataLoader using the feature extractor model\n",
    "def extract_features_batch(model, loader):\n",
    "    features = []\n",
    "    labels = []\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, label in loader:\n",
    "            # Move inputs to GPU if available\n",
    "            inputs = inputs.cuda() if torch.cuda.is_available() else inputs\n",
    "\n",
    "            # Pass the batch through the feature extractor\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Flatten and convert to NumPy arrays\n",
    "            features.append(outputs.cpu().numpy())  # Move outputs to CPU before converting to NumPy\n",
    "            labels.append(label.cpu().numpy())  # Move labels to CPU before converting\n",
    "\n",
    "    # Concatenate all batches into a single array\n",
    "    return np.concatenate(features), np.concatenate(labels)\n",
    "\n",
    "# Move model to GPU if available\n",
    "feature_extractor = feature_extractor.cuda() if torch.cuda.is_available() else feature_extractor\n",
    "\n",
    "# Extract features for the entire dataset using batch processing\n",
    "train_features, train_labels = extract_features_batch(feature_extractor, train_loader)\n",
    "\n",
    "# Print the shape of the extracted features\n",
    "print(f\"Extracted feature shape: {train_features.shape}\")\n",
    "#10661, 512, 1, 1 = 10661 testing images\n",
    "# 512 features for each image\n",
    "# 1,1 are the height and width as the image is convolved and pooled in resnet34 the final height and width will be 1,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34342e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T09:09:56.386315Z",
     "iopub.status.busy": "2024-10-26T09:09:56.386013Z",
     "iopub.status.idle": "2024-10-26T09:10:28.570243Z",
     "shell.execute_reply": "2024-10-26T09:10:28.569116Z"
    },
    "papermill": {
     "duration": 32.206288,
     "end_time": "2024-10-26T09:10:28.581778",
     "exception": false,
     "start_time": "2024-10-26T09:09:56.375490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Same for the images for the validation\n",
    "validation_features, validation_labels = extract_features_batch(feature_extractor, validation_loader)\n",
    "\n",
    "#Here we are reshaping the image to remove 1,1 as they aren't required info.\n",
    "train_features_flat = train_features.reshape(train_features.shape[0], 512)\n",
    "validation_features_flat = validation_features.reshape(validation_features.shape[0], 512)\n",
    "\n",
    "# Print the shape of the validation features\n",
    "print(f\"Validation features shape: {validation_features_flat.shape}\")\n",
    "print(f\"Train features shape: {train_features_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403f5e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T09:10:28.602160Z",
     "iopub.status.busy": "2024-10-26T09:10:28.601824Z",
     "iopub.status.idle": "2024-10-26T09:10:29.513315Z",
     "shell.execute_reply": "2024-10-26T09:10:29.512486Z"
    },
    "papermill": {
     "duration": 0.924292,
     "end_time": "2024-10-26T09:10:29.515567",
     "exception": false,
     "start_time": "2024-10-26T09:10:28.591275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Here, we have used two different inputs to analyze the model performance, one is directly passing 512 features as input\n",
    "#The second one is to reduce them to 50, using Principal Component analysis technique\n",
    "#PCA works by determining Principal components for the data and selecting top k PCs with highest variance coverage\n",
    "#If you need to learn more about PCA, refer: PCA Learning Docs by IBM\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensions to 50 using PCA\n",
    "pca = PCA(n_components=50)\n",
    "train_features_pca = pca.fit_transform(train_features_flat)\n",
    "validation_features_pca = pca.transform(validation_features_flat)\n",
    "\n",
    "print(f\"Reduced training feature shape: {train_features_pca.shape}\")\n",
    "print(f\"Reduced validation feature shape: {validation_features_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4bd568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T09:10:29.586251Z",
     "iopub.status.busy": "2024-10-26T09:10:29.585743Z",
     "iopub.status.idle": "2024-10-26T09:12:47.236939Z",
     "shell.execute_reply": "2024-10-26T09:12:47.235999Z"
    },
    "papermill": {
     "duration": 137.693224,
     "end_time": "2024-10-26T09:12:47.239035",
     "exception": false,
     "start_time": "2024-10-26T09:10:29.545811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Here are the instance of each ML technique  we are gonna implement\n",
    "#With probablities=True it will output the probabilities of the classes instead of just class label\n",
    "#Incase of inbalanced data, balance will make sure that the model is not fed with imbalanced data\n",
    "svm_clf = SVC(probability=True, class_weight='balanced')\n",
    "log_clf = LogisticRegression(max_iter=1000, class_weight='balanced')  # Logistic Regression\n",
    "dt_clf = DecisionTreeClassifier()  # Decision Tree\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm_clf), ('log', log_clf), ('dt', dt_clf)], voting='soft')\n",
    "\n",
    "voting_clf.fit(train_features_flat, train_labels)\n",
    "#dt_clf.fit(train_features_pca, train_labels)\n",
    "\n",
    "y_pred = voting_clf.predict(validation_features_flat)\n",
    "# y_pred = dt_clf.predict(validation_features_pca)\n",
    "\n",
    "accuracy = accuracy_score(validation_labels, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(classification_report(validation_labels, y_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(validation_labels, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['Hem', 'All'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8deb3f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-26T09:12:47.260865Z",
     "iopub.status.busy": "2024-10-26T09:12:47.260260Z",
     "iopub.status.idle": "2024-10-26T09:12:47.800074Z",
     "shell.execute_reply": "2024-10-26T09:12:47.798794Z"
    },
    "papermill": {
     "duration": 0.552658,
     "end_time": "2024-10-26T09:12:47.801763",
     "exception": true,
     "start_time": "2024-10-26T09:12:47.249105",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "#Now the resnet 34 was developed for classification of 1k classes, but as we want it for 2, we are updating the final FC layer\n",
    "# Modify the fully connected layer to match the number of output classes (Hem and All)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_ftrs, 2)  # 2 output classes for Hem and All\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet34 = resnet.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe184e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T16:56:41.784275Z",
     "iopub.status.busy": "2024-10-25T16:56:41.783407Z",
     "iopub.status.idle": "2024-10-25T16:56:41.795151Z",
     "shell.execute_reply": "2024-10-25T16:56:41.794168Z",
     "shell.execute_reply.started": "2024-10-25T16:56:41.784229Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Set up the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross Entropy Loss for classification\n",
    "#Optimizers are used to get the best Weights and Bias pair, over time.\n",
    "#Adam is a well known one, the first argument tells which all parameters are to be updated, in our case all\n",
    "#learning rate=0.001, weight_decay is for regularization purpose\n",
    "optimizer = optim.Adam(resnet34.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Training function for one epoch\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader: #The data will be processed batch wise, in our case 32\n",
    "        #Putting both of them to the available device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute training statistics\n",
    "        #This will provide us with the 0 or 1 class value based on the maximum values\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        #This computed the total running loss over all the batches\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        #Number of correct predictions over all\n",
    "        correct += (preds == labels).sum().item()\n",
    "        #It is possible that the last batch can be partially empty so getting the actual length\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    # Calculate training loss and accuracy\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    epoch_error = 1 - epoch_acc  # Error = 1 - Accuracy\n",
    "    \n",
    "    print(f\"Train Loss: {epoch_loss:.4f} | Train Accuracy: {epoch_acc * 100:.2f}% | Train Error: {epoch_error * 100:.2f}% | Correct: {correct}\")\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc696240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T16:13:42.546213Z",
     "iopub.status.busy": "2024-10-25T16:13:42.545279Z",
     "iopub.status.idle": "2024-10-25T16:13:42.554764Z",
     "shell.execute_reply": "2024-10-25T16:13:42.553760Z",
     "shell.execute_reply.started": "2024-10-25T16:13:42.546168Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing function for one epoch\n",
    "def test_epoch(model, validation_loader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for inputs, labels in validation_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Compute validation statistics\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            # Store all predictions and labels for further analysis\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate validation loss and accuracy\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    epoch_error = 1 - epoch_acc  # Error = 1 - Accuracy\n",
    "    \n",
    "    print(f\"Validation Loss: {epoch_loss:.4f} | Validation Accuracy: {epoch_acc * 100:.2f}% | Validation Error: {epoch_error * 100:.2f}% | Correct: {correct}\")\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361c623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T16:56:52.727669Z",
     "iopub.status.busy": "2024-10-25T16:56:52.727284Z",
     "iopub.status.idle": "2024-10-25T17:06:42.431909Z",
     "shell.execute_reply": "2024-10-25T17:06:42.430582Z",
     "shell.execute_reply.started": "2024-10-25T16:56:52.727633Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 8  # Number of epochs to train\n",
    "\n",
    "# Lists to track losses, accuracies, and errors over epochs\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "train_errors = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_errors = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss, train_acc, train_error = train_epoch(resnet34, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    train_errors.append(train_error)\n",
    "    \n",
    "    # Validate after each epoch\n",
    "    val_loss, val_acc, val_error = test_epoch(resnet34, validation_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_errors.append(val_error)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 849724,
     "sourceId": 1449674,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 337.397994,
   "end_time": "2024-10-26T09:12:49.433980",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-26T09:07:12.035986",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
